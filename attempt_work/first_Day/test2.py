import asyncio
import aiohttp
import time
import aiofiles


async def download_single(session, url, save_path, index):
    """ä¸‹è½½å•ä¸ªæ–‡ä»¶ - æ·»åŠ è¯¦ç»†æ—¥å¿—"""
    print(f"ğŸš€ ä»»åŠ¡{index} å¼€å§‹: {url}")
    start_time = time.time()

    try:
        async with session.get(url) as response:
            request_time = time.time() - start_time
            print(f"ğŸ“¥ ä»»åŠ¡{index} æ”¶åˆ°å“åº”: {response.status} (è¯·æ±‚è€—æ—¶: {request_time:.2f}s)")

            if response.status == 200:
                await asyncio.sleep(1)
                content = await response.read()
                read_time = time.time() - start_time - request_time
                print(f"ğŸ“– ä»»åŠ¡{index} è¯»å–å†…å®¹å®Œæˆ (è¯»å–è€—æ—¶: {read_time:.2f}s)")
                await asyncio.sleep(1)
                async with aiofiles.open(save_path, 'wb') as f:
                    await f.write(content)

                total_time = time.time() - start_time
                print(f"âœ… ä»»åŠ¡{index} å®Œæˆ: æ€»è€—æ—¶ {total_time:.2f}s")
                return True, f"ä¸‹è½½æˆåŠŸ: {url}"
            else:
                total_time = time.time() - start_time
                print(f"âŒ ä»»åŠ¡{index} HTTPé”™è¯¯: {response.status} (æ€»è€—æ—¶: {total_time:.2f}s)")
                return False, f"HTTPé”™è¯¯: {response.status}"
    except Exception as e:
        total_time = time.time() - start_time
        print(f"ğŸ’¥ ä»»åŠ¡{index} å¼‚å¸¸: {e} (æ€»è€—æ—¶: {total_time:.2f}s)")
        return False, f"é”™è¯¯: {str(e)}"


async def download_multiple_async(urls, save_dir):
    """å¼‚æ­¥å¹¶å‘ä¸‹è½½å¤šä¸ªæ–‡ä»¶"""
    print(f"ğŸ”„ å¼€å§‹å¹¶å‘ä¸‹è½½ {len(urls)} ä¸ªURL")
    start_time = time.time()

    async with aiohttp.ClientSession() as session:
        tasks = [download_single(session, url, f"{save_dir}/webpage_{i}.html", i)
                 for i, url in enumerate(urls)]
        results = await asyncio.gather(*tasks)

        total_time = time.time() - start_time
        print(f"ğŸ¯ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}s")
        return results


def main():
    """ä¸»å‡½æ•°"""
    test_urls = [
        "http://httpbin.org/ip",  # å¿«é€Ÿå“åº”
        "http://httpbin.org/user-agent",  # å¿«é€Ÿå“åº”
        "http://httpbin.org/delay/2",  # 2ç§’å»¶è¿Ÿ
    ]
    url = "http://47.76.50.153:8000/"
    test_urls = [url] * 100
    print("=== å¼‚æ­¥å¹¶å‘ä¸‹è½½æµ‹è¯• ===")
    print(f"æµ‹è¯•URLs: {test_urls}")
    print()

    start_time = time.time()
    results = asyncio.run(download_multiple_async(test_urls, "downloaded_pages"))
    elapsed_time = time.time() - start_time

    print(f"\nâ±ï¸ æ€»è¿è¡Œæ—¶é—´: {elapsed_time:.6f} ç§’")

    # åˆ†æç»“æœ
    if elapsed_time < 4:  # å¦‚æœæ€»æ—¶é—´å°äº4ç§’ï¼Œè¯´æ˜å¹¶å‘æœ‰æ•ˆ
        print("âœ… å¼‚æ­¥å¹¶å‘å·¥ä½œæ­£å¸¸ï¼")
    else:
        print("âŒ å¼‚æ­¥å¹¶å‘å¯èƒ½æœªæ­£å¸¸å·¥ä½œ")

    for success, message in results:
        status = "âœ…" if success else "âŒ"
        print(f"{status} {message}")


if __name__ == "__main__":
    main()